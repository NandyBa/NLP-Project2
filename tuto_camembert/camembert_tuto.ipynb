{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fast_bert\n",
      "  Downloading fast_bert-1.9.12-py3-none-any.whl (99 kB)\n",
      "     |████████████████████████████████| 99 kB 534 kB/s            \n",
      "\u001b[?25hCollecting tokenizers==0.8.1.rc1\n",
      "  Downloading tokenizers-0.8.1rc1.tar.gz (97 kB)\n",
      "     |████████████████████████████████| 97 kB 222 kB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting transformers==3.0.2\n",
      "  Downloading transformers-3.0.2-py3-none-any.whl (769 kB)\n",
      "     |████████████████████████████████| 769 kB 385 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: matplotlib in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from fast_bert) (3.5.1)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "     |████████████████████████████████| 43 kB 285 kB/s            \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pytorch-lamb\n",
      "  Downloading pytorch_lamb-1.0.0-py3-none-any.whl (4.4 kB)\n",
      "Requirement already satisfied: pandas in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from fast_bert) (1.3.5)\n",
      "Collecting python-box\n",
      "  Downloading python_box-5.4.1-py3-none-any.whl (21 kB)\n",
      "Collecting tensorboardX\n",
      "  Downloading tensorboardX-2.4.1-py2.py3-none-any.whl (124 kB)\n",
      "     |████████████████████████████████| 124 kB 221 kB/s            \n",
      "\u001b[?25hCollecting spacy\n",
      "  Downloading spacy-3.2.1.tar.gz (1.1 MB)\n",
      "     |████████████████████████████████| 1.1 MB 314 kB/s            \n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: sklearn in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from fast_bert) (0.0)\n",
      "Collecting more-itertools\n",
      "  Downloading more_itertools-8.12.0-py3-none-any.whl (54 kB)\n",
      "     |████████████████████████████████| 54 kB 439 kB/s            \n",
      "\u001b[?25hCollecting fastprogress\n",
      "  Downloading fastprogress-1.0.0-py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers==3.0.2->fast_bert) (1.21.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers==3.0.2->fast_bert) (2021.4.4)\n",
      "Requirement already satisfied: requests in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers==3.0.2->fast_bert) (2.26.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers==3.0.2->fast_bert) (4.62.3)\n",
      "Collecting sentencepiece!=0.1.92\n",
      "  Using cached sentencepiece-0.1.96.tar.gz (508 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacremoses\n",
      "  Using cached sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
      "Requirement already satisfied: packaging in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from transformers==3.0.2->fast_bert) (21.3)\n",
      "Collecting filelock\n",
      "  Using cached filelock-3.4.2-py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from matplotlib->fast_bert) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from matplotlib->fast_bert) (4.28.5)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from matplotlib->fast_bert) (8.4.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from matplotlib->fast_bert) (0.11.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from matplotlib->fast_bert) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from matplotlib->fast_bert) (3.0.6)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pandas->fast_bert) (2021.3)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.11.2-cp39-cp39-macosx_11_0_arm64.whl (552 kB)\n",
      "     |████████████████████████████████| 552 kB 137 kB/s            \n",
      "\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pytorch-lamb->fast_bert) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from seqeval->fast_bert) (1.0.1)\n",
      "Collecting blis<0.8.0,>=0.4.0\n",
      "  Using cached blis-0.7.5-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting typer<0.5.0,>=0.3.0\n",
      "  Using cached typer-0.4.0-py3-none-any.whl (27 kB)\n",
      "Collecting thinc<8.1.0,>=8.0.12\n",
      "  Using cached thinc-8.0.13-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting cymem<2.1.0,>=2.0.2\n",
      "  Using cached cymem-2.0.6-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Requirement already satisfied: setuptools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy->fast_bert) (60.2.0)\n",
      "Collecting pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4\n",
      "  Using cached pydantic-1.8.2-py3-none-any.whl (126 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2\n",
      "  Using cached preshed-3.0.6-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0\n",
      "  Downloading spacy_loggers-1.0.1-py3-none-any.whl (7.0 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0\n",
      "  Using cached murmurhash-1.0.6-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting wasabi<1.1.0,>=0.8.1\n",
      "  Using cached wasabi-0.9.0-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from spacy->fast_bert) (2.11.3)\n",
      "Collecting langcodes<4.0.0,>=3.2.0\n",
      "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
      "     |████████████████████████████████| 181 kB 375 kB/s            \n",
      "\u001b[?25hCollecting pathy>=0.3.5\n",
      "  Using cached pathy-0.6.1-py3-none-any.whl (42 kB)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.8\n",
      "  Downloading spacy_legacy-3.0.8-py2.py3-none-any.whl (14 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.1\n",
      "  Using cached srsly-2.4.2-cp39-cp39-macosx_11_0_arm64.whl\n",
      "Collecting catalogue<2.1.0,>=2.0.6\n",
      "  Using cached catalogue-2.0.6-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from tensorboardX->fast_bert) (3.15.8)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pathy>=0.3.5->spacy->fast_bert) (5.2.1)\n",
      "Requirement already satisfied: six>=1.9 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from protobuf>=3.8.0->tensorboardX->fast_bert) (1.15.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4->spacy->fast_bert) (3.7.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers==3.0.2->fast_bert) (3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers==3.0.2->fast_bert) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers==3.0.2->fast_bert) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from requests->transformers==3.0.2->fast_bert) (1.26.7)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->fast_bert) (1.7.3)\n",
      "Requirement already satisfied: joblib>=0.11 in /Users/nandyba/.local/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->fast_bert) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from scikit-learn>=0.21.3->seqeval->fast_bert) (3.0.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from typer<0.5.0,>=0.3.0->spacy->fast_bert) (7.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages (from jinja2->spacy->fast_bert) (1.1.1)\n",
      "Building wheels for collected packages: tokenizers, seqeval, spacy, sentencepiece\n",
      "  Building wheel for tokenizers (pyproject.toml) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/pip/_vendor/pep517/in_process/_in_process.py build_wheel /var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/tmpdkvp0mhg\n",
      "       cwd: /private/var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/pip-install-cc85om8_/tokenizers_e9a99f7b88a54620bd616e8be4c84296\n",
      "  Complete output (47 lines):\n",
      "  /private/var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/pip-build-env-mv3en2pb/overlay/lib/python3.9/site-packages/setuptools/dist.py:493: UserWarning: Normalizing '0.8.1.rc1' to '0.8.1rc1'\n",
      "    warnings.warn(tmpl.format(**locals()))\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-11.0-arm64-3.9\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers\n",
      "  copying tokenizers/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/models\n",
      "  copying tokenizers/models/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/models\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/decoders\n",
      "  copying tokenizers/decoders/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/decoders\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/normalizers\n",
      "  copying tokenizers/normalizers/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/normalizers\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/pre_tokenizers\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/processors\n",
      "  copying tokenizers/processors/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/processors\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/trainers\n",
      "  copying tokenizers/trainers/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/trainers\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/implementations/byte_level_bpe.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/implementations/sentencepiece_bpe.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/implementations/base_tokenizer.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/implementations/__init__.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/implementations/char_level_bpe.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/implementations/bert_wordpiece.py -> build/lib.macosx-11.0-arm64-3.9/tokenizers/implementations\n",
      "  copying tokenizers/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers\n",
      "  copying tokenizers/models/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers/models\n",
      "  copying tokenizers/decoders/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers/decoders\n",
      "  copying tokenizers/normalizers/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers/normalizers\n",
      "  copying tokenizers/pre_tokenizers/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers/pre_tokenizers\n",
      "  copying tokenizers/processors/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers/processors\n",
      "  copying tokenizers/trainers/__init__.pyi -> build/lib.macosx-11.0-arm64-3.9/tokenizers/trainers\n",
      "  running build_ext\n",
      "  error: can't find Rust compiler\n",
      "  \n",
      "  If you are using an outdated pip version, it is possible a prebuilt wheel is available for this package but pip is not able to install from it. Installing from the wheel would avoid the need for a Rust compiler.\n",
      "  \n",
      "  To update pip, run:\n",
      "  \n",
      "      pip install --upgrade pip\n",
      "  \n",
      "  and then retry package installation.\n",
      "  \n",
      "  If you did intend to build this package from source, try installing a Rust compiler from your system package manager and ensure it is on the PATH during installation. Alternatively, rustup (available at https://rustup.rs) is the recommended way to download and update the Rust compiler toolchain.\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for tokenizers\u001b[0m\n",
      "\u001b[?25h  Building wheel for seqeval (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=4714f026df5e74a058ec6d164d4c86f08a4c62504b737c7dfdc7c39832a937d2\n",
      "  Stored in directory: /Users/nandyba/Library/Caches/pip/wheels/e2/a5/92/2c80d1928733611c2747a9820e1324a6835524d9411510c142\n",
      "  Building wheel for spacy (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for spacy: filename=spacy-3.2.1-cp39-cp39-macosx_11_0_arm64.whl size=1313042 sha256=b637ece5361c8bd17f019f65e4464f9b040bf0013d9f45dd0ece3a43a6bbda79\n",
      "  Stored in directory: /Users/nandyba/Library/Caches/pip/wheels/f2/d3/33/635eb06dec7bbcb106db90d4cf82a2d37b91c6ab60239a4db0\n",
      "  Building wheel for sentencepiece (setup.py) ... \u001b[?25lerror\n",
      "\u001b[31m  ERROR: Command errored out with exit status 1:\n",
      "   command: /opt/homebrew/Caskroom/miniforge/base/bin/python3.9 -u -c 'import io, os, sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/private/var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/pip-install-cc85om8_/sentencepiece_fb61f636ffec4c5a9d09d46d51290bc7/setup.py'\"'\"'; __file__='\"'\"'/private/var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/pip-install-cc85om8_/sentencepiece_fb61f636ffec4c5a9d09d46d51290bc7/setup.py'\"'\"';f = getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__) if os.path.exists(__file__) else io.StringIO('\"'\"'from setuptools import setup; setup()'\"'\"');code = f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /private/var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/pip-wheel-41esti4x\n",
      "       cwd: /private/var/folders/ts/pmyrp_gn1tq7475xr1zcwbwm0000gn/T/pip-install-cc85om8_/sentencepiece_fb61f636ffec4c5a9d09d46d51290bc7/\n",
      "  Complete output (37 lines):\n",
      "  /opt/homebrew/Caskroom/miniforge/base/lib/python3.9/site-packages/setuptools/dist.py:723: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "    warnings.warn(\n",
      "  running bdist_wheel\n",
      "  running build\n",
      "  running build_py\n",
      "  creating build\n",
      "  creating build/lib.macosx-11.0-arm64-3.9\n",
      "  creating build/lib.macosx-11.0-arm64-3.9/sentencepiece\n",
      "  copying src/sentencepiece/__init__.py -> build/lib.macosx-11.0-arm64-3.9/sentencepiece\n",
      "  copying src/sentencepiece/sentencepiece_model_pb2.py -> build/lib.macosx-11.0-arm64-3.9/sentencepiece\n",
      "  copying src/sentencepiece/sentencepiece_pb2.py -> build/lib.macosx-11.0-arm64-3.9/sentencepiece\n",
      "  running build_ext\n",
      "  /bin/sh: pkg-config: command not found\n",
      "  Cloning into 'sentencepiece'...\n",
      "  Note: switching to 'd8711f55d9b2cb9c77a00adcc18108482b29b675'.\n",
      "  \n",
      "  You are in 'detached HEAD' state. You can look around, make experimental\n",
      "  changes and commit them, and you can discard any commits you make in this\n",
      "  state without impacting any branches by switching back to a branch.\n",
      "  \n",
      "  If you want to create a new branch to retain commits you create, you may\n",
      "  do so (now or later) by using -c with the switch command. Example:\n",
      "  \n",
      "    git switch -c <new-branch-name>\n",
      "  \n",
      "  Or undo this operation with:\n",
      "  \n",
      "    git switch -\n",
      "  \n",
      "  Turn off this advice by setting config variable advice.detachedHead to false\n",
      "  \n",
      "  ./build_bundled.sh: line 15: cmake: command not found\n",
      "  ./build_bundled.sh: line 16: nproc: command not found\n",
      "  make: *** No targets specified and no makefile found.  Stop.\n",
      "  make: *** No rule to make target `install'.  Stop.\n",
      "  env: pkg-config: No such file or directory\n",
      "  Failed to find sentencepiece pkg-config\n",
      "  ----------------------------------------\u001b[0m\n",
      "\u001b[31m  ERROR: Failed building wheel for sentencepiece\u001b[0m\n",
      "\u001b[?25h  Running setup.py clean for sentencepiece\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully built seqeval spacy\r\n",
      "Failed to build tokenizers sentencepiece\r\n",
      "\u001b[31mERROR: Could not build wheels for tokenizers, which is required to install pyproject.toml-based projects\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install fast_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fast_bert'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3b35af1693f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_cls\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertDataBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_cls\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_lm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertLMDataBunch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfast_bert\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearner_lm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertLMLearner\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fast_bert'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from fast_bert.data_cls import BertDataBunch\n",
    "from fast_bert.learner_cls import BertLearner\n",
    "from fast_bert.data_lm import BertLMDataBunch\n",
    "from fast_bert.learner_lm import BertLMLearner\n",
    "from fast_bert.metrics import fbeta, roc_auc\n",
    "from fast_bert.prediction import BertClassificationPredictor\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "\n",
    "logger = logging.getLogger()\n",
    "device_cuda = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('./data/')\n",
    "LOG_PATH = Path('./logs/')\n",
    "MODEL_PATH = Path('./model/')\n",
    "LABEL_PATH = Path('./labels/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/labeled_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_set = df.sample(frac=0.2, replace=False, random_state=42)\n",
    "train_set = df.drop(index = val_set.index)\n",
    "print('Nombre de commentaires dans le val_set:',len(val_set))\n",
    "print('Nombre de commentaires dans le train_set:', len(train_set))\n",
    "val_set.to_csv('./data/val_set.csv')\n",
    "train_set.to_csv('.data/train_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df.columns[2:].to_list()\n",
    "with open('./labels/labels.txt', 'w') as f:\n",
    "    for i in labels:\n",
    "        f.write(i + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_texts = pd.read_csv('./data/raw_data.csv')\n",
    "all_texts = df_texts['caption'].to_list()\n",
    "print('Nombre de commentaires:', len(all_texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de LMDataBunch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch_lm = BertLMDataBunch.from_raw_corpus(\n",
    "                    data_dir=DATA_PATH,\n",
    "                    text_list=all_texts,\n",
    "                    tokenizer='camembert-base',\n",
    "                    batch_size_per_gpu=16,\n",
    "                    max_seq_length=512,\n",
    "                    multi_gpu=False,\n",
    "                    model_type='camembert-base',\n",
    "                    logger=logger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de LMLearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learner = BertLMLearner.from_pretrained_model(\n",
    "                            dataBunch=databunch_lm,\n",
    "                            pretrained_path='camembert-base',\n",
    "                            output_dir=MODEL_PATH,\n",
    "                            metrics=[],\n",
    "                            device=device_cuda,\n",
    "                            logger=logger,\n",
    "                            multi_gpu=False,\n",
    "                            logging_steps=50,\n",
    "                            fp16_opt_level=\"O2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learner.fit(epochs=30,\n",
    "            lr=1e-4,\n",
    "            validate=True,\n",
    "            schedule_type=\"warmup_cosine\",\n",
    "            optimizer_type=\"adamw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de databunch pour la classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n",
    "                          tokenizer='camembert-base',\n",
    "                          train_file='train_set.csv',\n",
    "                          val_file='val_set.csv',\n",
    "                          label_file='labels.txt',\n",
    "                          text_col='review',\n",
    "                          label_col=['cadre/atmosphère','probleme technique',\"temps d'attente\",'accueil/relation commerciale'],\n",
    "                          batch_size_per_gpu=16,\n",
    "                          max_seq_length=512,\n",
    "                          multi_gpu=False,\n",
    "                          multi_label=True,\n",
    "                          model_type='camembert-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Création de Learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [{'name': 'fbeta', 'function': fbeta}, {'name': 'roc_auc', 'function': roc_auc}]\n",
    "OUTPUT_DIR = Path('./finetuned_model')\n",
    "WGTS_PATH = Path('model/model_out/pytorch_model.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_learner = BertLearner.from_pretrained_model(\n",
    "                        databunch,\n",
    "                        pretrained_path='model/model_out',\n",
    "                        metrics=metrics,\n",
    "                        device=device_cuda,\n",
    "                        logger=logger,\n",
    "                        output_dir=OUTPUT_DIR,\n",
    "                        finetuned_wgts_path=WGTS_PATH,\n",
    "                        warmup_steps=300,\n",
    "                        multi_gpu=False,\n",
    "                        multi_label=True,\n",
    "                        is_fp16=True,\n",
    "                        logging_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_learner.fit(epochs=30,\n",
    "            lr=9e-5,\n",
    "            validate=True,\n",
    "            schedule_type=\"warmup_cosine\",\n",
    "            optimizer_type=\"adamw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_learner.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_learner.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = BertClassificationPredictor(\n",
    "                model_path='finetuned_model/model_out',\n",
    "                label_path='labels/',\n",
    "                multi_label=True,\n",
    "                model_type='camembert-base',\n",
    "                do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.predict(\"Texte à classer\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
